{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c26qNOlCyXb"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and labels\n",
        "path = \"../input/\"\n",
        "train_path = os.path.join(path, 'train/')\n",
        "df = pd.DataFrame({'path': glob(os.path.join(train_path, '*.tif'))})\n",
        "df['id'] = df.path.map(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
        "labels = pd.read_csv(os.path.join(path, \"train_labels.csv\"))\n",
        "df = df.merge(labels, on=\"id\")"
      ],
      "metadata": {
        "id": "_ggfiq7vDgaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sample images\n",
        "N = 10000\n",
        "X, y = [], []\n",
        "for i, row in tqdm(df.iterrows(), total=N):\n",
        "    img = cv2.imread(row['path'])\n",
        "    X.append(img)\n",
        "    y.append(row['label'])\n",
        "    if i == N - 1:\n",
        "        break\n",
        "\n",
        "X, y = np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "ctFRtD0lDZ43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a few sample images with labels\n",
        "plt.figure(figsize=(10, 4), dpi=150)\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(X[i])\n",
        "    plt.title(f'Label: {y[i]}')\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "plt.suptitle('Sample Images with Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3kjNQEgcDW0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display class distribution\n",
        "plt.figure(figsize=(4, 2), dpi=150)\n",
        "plt.bar(['Positive', 'Negative'], [(y == 1).sum(), (y == 0).sum()])\n",
        "plt.ylabel(\"# of samples\")\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hs6JsGFRDVDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display pixel value distributions\n",
        "def plot_pixel_value_distributions(samples, title):\n",
        "    plt.figure(figsize=(8, 6), dpi=150)\n",
        "    for i in range(3):\n",
        "        plt.subplot(2, 2, i + 1)\n",
        "        plt.hist(samples[:, :, :, i].flatten(), bins=256, density=True, color=['red', 'green', 'blue'][i])\n",
        "        plt.ylabel(\"Relative frequency\")\n",
        "        plt.xlabel(\"Pixel value\")\n",
        "        plt.title(f\"{['Red', 'Green', 'Blue'][i]} Channel\")\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.hist(samples.flatten(), bins=256, density=True, color='gray')\n",
        "    plt.ylabel(\"Relative frequency\")\n",
        "    plt.xlabel(\"Pixel value\")\n",
        "    plt.title(\"RGB Channel\")\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "positive_samples = X[y == 1]\n",
        "negative_samples = X[y == 0]\n",
        "plot_pixel_value_distributions(positive_samples, 'Pixel Value Distributions - Positive Samples')\n",
        "plot_pixel_value_distributions(negative_samples, 'Pixel Value Distributions - Negative Samples')"
      ],
      "metadata": {
        "id": "hVs6FfZFDRvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = df[\"path\"].size\n",
        "X, y = [], []\n",
        "for i, row in tqdm(df.iterrows(), total=N):\n",
        "    img = cv2.imread(row['path'])\n",
        "    X.append(img)\n",
        "    y.append(row['label'])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Split data into training and validation sets using train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "m3rlMLFbDDvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(96, 96, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "WKzCieeIDCNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compilation\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "batch_size = 50\n",
        "epochs = 3\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "# Model evaluation\n",
        "loss, acc = model.evaluate(X_val, y_val)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "Q129x6ntC_vT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}